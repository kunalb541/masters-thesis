\chapter{Literature Review}
\label{ch:literature}

The automated classification of gravitational microlensing events represents a confluence of three distinct research areas: observational astronomy and survey operations, gravitational lensing theory and modeling, and machine learning for time-series analysis. This chapter provides a comprehensive survey of related work across these domains, establishing the scientific and technical context for the CNN-GRU hierarchical classifier developed in this thesis.

We begin by reviewing the history and current operational state of microlensing surveys (\cref{sec:surveys}), focusing on their detection strategies, data products, and classification challenges. We then examine traditional approaches to binary microlensing classification, including $\chi^2$ model fitting and Bayesian inference methods (\cref{sec:traditional}), emphasizing their computational costs and observational requirements that limit real-time applicability. Next, we survey machine learning applications in time-domain astronomy (\cref{sec:ml_astronomy}), covering both classical feature-based methods and recent deep learning architectures for light curve classification. Special attention is given to early classification problems in other astronomical transient domains (\cref{sec:early_classification}) where similar temporal challenges arise. We conclude by synthesizing these perspectives to identify the specific research gap addressed by this work: the absence of end-to-end sequential modeling approaches designed for real-time binary microlensing classification (\cref{sec:gap}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Microlensing Surveys and Detection Strategies}
\label{sec:surveys}

\subsection{Ground-Based Survey Operations}

The modern era of gravitational microlensing began in the early 1990s with the establishment of two pioneering surveys: the Optical Gravitational Lensing Experiment (OGLE) and Microlensing Observations in Astrophysics (MOA). Both surveys monitor millions of stars in the Galactic bulge and Magellanic Clouds, searching for the characteristic symmetric brightness variations produced by lensing events \citep{Udalski2015,Bond2017}.

OGLE, operating from Las Campanas Observatory in Chile, has evolved through four generations of instrumentation, with OGLE-IV monitoring approximately 200 million stars across the Galactic bulge at cadences ranging from 20 minutes (high-priority fields) to several days (low-priority fields) \citep{Udalski2015}. The survey discovers approximately 2,000 microlensing events annually, with several hundred showing anomalies potentially indicative of binary lens systems. OGLE's long baseline (over 30 years of operation) provides a vast archival dataset for testing classification algorithms, though the manual inspection process used to identify binary candidates introduces selection biases that are difficult to quantify retrospectively.

The Korea Microlensing Telescope Network (KMTNet), operational since 2015, employs three identical 1.6-meter telescopes distributed in longitude (Chile, South Africa, Australia) to provide near-continuous monitoring of the Galactic bulge \citep{Kim2018}. This geographic distribution partially mitigates the diurnal cycle that limits single-site surveys, enabling KMTNet to detect short-duration planetary caustic crossings that might be missed by OGLE's cadence. KMTNet's higher spatial resolution also reduces blending effects in crowded fields, improving photometric precision.

A common feature across these ground-based surveys is the two-stage detection architecture: initial event identification through difference imaging analysis to detect flux variations above a significance threshold, followed by human expert review of candidate light curves to distinguish genuine microlensing from variables, transients, and systematics. This manual bottleneck, acceptable when processing hundreds of events per year, becomes increasingly untenable as surveys scale to thousands of simultaneous events.

\subsection{Future Space-Based Observations}

The Nancy Grace Roman Space Telescope, scheduled for launch in 2027, represents a qualitative leap in microlensing survey capabilities \citep{Penny2019,Spergel2015}. Roman's Galactic Bulge Time-Domain Survey will monitor approximately 200 million stars with 15-minute cadence over 72-day seasons, achieving photometric precision significantly superior to ground-based facilities. The space-based platform eliminates weather interruptions, atmospheric seeing variations, and diurnal cycles, providing unprecedented temporal coverage \citep{Akeson2019}.

Simulations predict Roman will detect approximately 27,000 microlensing events over its five-year prime mission, with thousands of events exhibiting binary lens signatures \citep{Penny2019,Street2018}. This anticipated detection rate---more than an order of magnitude larger than current ground-based surveys---fundamentally changes the classification problem from one manageable through expert inspection to one requiring automated, real-time decision-making systems. The operational requirement for rapid classification stems from the need to coordinate follow-up observations: when Roman detects the onset of a caustic crossing event, ground-based networks must be alerted within hours to enable intensive monitoring during the scientifically valuable high-magnification phase.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Traditional Classification Approaches}
\label{sec:traditional}

\subsection{Chi-Squared Model Fitting}

The standard approach to microlensing event characterization relies on nonlinear least-squares fitting of physical models to observed light curves \citep{Gaudi2012}. For single-lens events, the point-source point-lens (PSPL) model contains only three free parameters---the Einstein crossing time $t_E$, impact parameter $u_0$, and time of closest approach $t_0$---and can be fit efficiently using standard optimization algorithms.

Binary lens models present significantly greater computational challenges. The minimum parameterization requires seven quantities: the three PSPL parameters plus the mass ratio $q$, projected separation $s$, source trajectory angle $\alpha$, and finite source size $\rho$ when applicable \citep{Dong2006}. The parameter space contains numerous local minima corresponding to qualitatively different binary topologies, and global optimization often requires Markov Chain Monte Carlo sampling to characterize the posterior distribution adequately.

The computational cost of binary model fitting scales poorly with data volume. Fitting a single binary model to a typical light curve requires minutes of computation using numerical ray-shooting codes such as VBBinaryLensing \citep{Bozza2010}, and characterizing the posterior distribution across all seven parameters can require hours. When multiplied across thousands of ongoing events that must be refitted with each new observation, the computational burden becomes prohibitive for real-time survey operations. This computational bottleneck---rather than fundamental limitations of the fitting approach---motivates the exploration of machine learning alternatives that can provide rapid approximate classifications to triage which events warrant intensive modeling.

\subsection{Bayesian Inference Methods}

Several groups have developed Bayesian frameworks for microlensing classification that incorporate prior knowledge about lens populations and selection effects \citep{Suzuki2016}. These approaches compute posterior probabilities over model classes (PSPL versus binary) given the observed photometry, naturally accounting for parameter degeneracies and providing uncertainty quantification.

While Bayesian methods offer principled probabilistic reasoning, they face the same computational challenges as $\chi^2$ fitting: computing the model evidence for binary lens configurations requires marginalizing over the high-dimensional parameter space, which is computationally expensive. Approximate Bayesian computation and nested sampling algorithms can reduce these costs but still require minutes to hours per event for reliable results. For real-time survey operations requiring sub-second decisions on thousands of events, these timescales remain impractical.

\subsection{Expert Visual Inspection}

Current surveys rely heavily on human expert judgment to identify binary events. Experienced observers can often recognize subtle asymmetries, secondary peaks, or caustic crossing features that indicate binary structure, even in noisy or incomplete light curves. However, this approach suffers from several fundamental limitations: it is labor-intensive and does not scale to Roman-era detection rates, introduces subjective biases that vary between observers and over time, lacks quantitative uncertainty estimates needed for resource allocation decisions, and cannot provide the millisecond-scale response times required for automated alert systems.

These limitations motivate the development of automated classification systems that can replicate expert performance while providing consistent, rapid, and well-calibrated probabilistic outputs.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Machine Learning in Time-Domain Astronomy}
\label{sec:ml_astronomy}

\subsection{Classical Feature-Based Approaches}

Early applications of machine learning to astronomical time-series classification relied on engineered features extracted from light curves. Random forest classifiers, trained on summary statistics such as variability indices, periodicity measures, and shape parameters, achieved human-level performance on variable star classification tasks \citep{Wyrzykowski2015,VanderPlas2018}.

For microlensing specifically, \citet{Godines2019} developed a random forest classifier using 47 features computed from OGLE light curves, achieving approximately 94\% accuracy in distinguishing microlensing events from other transient phenomena. Similarly, \citet{Khakpash2021} designed 15 features intended to capture binary signatures—measures of peak smoothness, asymmetry metrics, and peak-counting statistics—and demonstrated promising results on simulated Roman data.

While these feature-based approaches provide interpretable models and require modest computational resources, they suffer from intrinsic limitations. The features must be hand-crafted by domain experts who anticipate relevant morphological signatures, but the morphological diversity of binary light curves means no fixed feature set can capture all possible binary configurations. Features computed from partial light curves may behave differently than those from complete events, requiring careful recalibration for real-time applications. The feature engineering process discards potentially useful information present in the raw photometric time series.

\subsection{Deep Learning for Light Curve Classification}

The emergence of deep learning offers an alternative paradigm: rather than engineering features manually, learn optimal representations directly from raw time-series data. Convolutional neural networks (CNNs) applied to astronomical light curves have demonstrated the viability of this approach across multiple domains.

For exoplanet transit detection, \citet{Shallue2018} trained a CNN on Kepler light curves and achieved human-expert-level accuracy in identifying planetary transit signatures, including the discovery of previously overlooked planetary candidates. The CNN learned to recognize transit shapes without explicit programming of duration, depth, or periodicity features.

In supernova classification, recurrent neural networks have proven particularly effective. The SuperNNova framework \citep{Moller2020} employs a bidirectional long short-term memory (LSTM) architecture trained on multi-band supernova photometry, achieving 97\% accuracy in distinguishing Type Ia from non-Ia supernovae. Critically, SuperNNova can classify events using only partial light curves observed up to maximum brightness, demonstrating that recurrent architectures can learn temporal dependencies relevant for early-time classification.

For variable star classification on irregularly sampled data, \citet{Naul2018} developed an autoencoding RNN that explicitly models observation times and heteroskedastic uncertainties, achieving competitive performance with feature-based methods while learning representations that transfer across different surveys.

\subsection{Applications to Microlensing}

Deep learning applications to microlensing remain limited compared to other time-domain phenomena. The most relevant precedent is the work of \citet{Mroz2020}, who applied simple feed-forward neural networks to binary microlensing classification. However, their approach required pre-computed PSPL model fits as input features, reintroducing the computational bottleneck of traditional methods. The networks achieved approximately 80--85\% accuracy on known binary events but could not operate on raw photometry.

More recently, \citet{Ishitani2022} developed a CNN for automated detection of microlensing events in the MOA survey, processing raw photometric time series without requiring model fits. Their system achieves millisecond-scale inference and discovered events missed by traditional pipelines. However, the CNN focuses on the detection problem (microlensing versus non-microlensing) rather than the more challenging task of distinguishing binary from single-lens events among genuine microlensing light curves.

The absence of end-to-end binary classification systems in the literature represents a significant gap, particularly given the operational requirements for Roman-era surveys.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Early Classification in Other Transient Domains}
\label{sec:early_classification}

The challenge of classifying astronomical transients from incomplete observations arises across multiple domains, providing instructive parallels for microlensing classification.

\subsection{Supernova Photometric Typing}

Supernova classification from photometric data alone (without spectroscopy) presents temporal challenges analogous to microlensing: observers must distinguish between spectroscopic types using only brightness evolution in multiple filters. Early classification is valuable for triggering spectroscopic follow-up while objects are bright and observable.

The Photometric LSST Astronomical Time-series Classification Challenge (PLAsTiCC) established benchmarks for early supernova classification \citep{Lochner2016}. Winning solutions combined recurrent neural networks with boosted decision trees, achieving high accuracy (>90\%) even when light curves contained only a few observations near maximum brightness. Key lessons include: preprocessing strategies that handle irregular sampling and missing data significantly impact performance, uncertainty quantification through Bayesian methods or Monte Carlo dropout helps guide follow-up decisions, and augmentation techniques that simulate different cadences improve robustness.

\subsection{Transient Identification in LSST}

The upcoming Legacy Survey of Space and Time (LSST) will generate millions of transient alerts nightly, requiring automated classification to identify scientifically valuable targets for follow-up \citep{Ivezic2019}. Broker systems under development employ machine learning classifiers trained on simulated LSST photometry to categorize alerts into supernova types, tidal disruption events, active galactic nuclei, and other classes.

A common challenge across these systems is handling the sequential nature of incoming data: each night brings new observations that should refine earlier classifications. Recurrent architectures provide a natural framework for this sequential updating, maintaining an internal state that evolves as new data arrives \citep{Naul2018}.

\subsection{Lessons for Microlensing Classification}

These transient classification efforts provide several insights relevant to microlensing:

\begin{enumerate}
\item \textbf{Sequential processing architectures} (RNNs, LSTMs, GRUs) naturally handle variable-length time series and can update classifications as observations arrive, making them well-suited for real-time applications.

\item \textbf{Hybrid architectures} combining CNNs for local feature extraction with RNNs for long-term memory have proven effective across multiple domains, suggesting this design may transfer to microlensing.

\item \textbf{Synthetic training data} is essential when real labeled examples are scarce or biased by selection effects. Physics-based simulation enables generation of unlimited training examples spanning the full parameter space.

\item \textbf{Calibrated uncertainty estimates} are critical for operational deployment. Models must not only predict class labels but also provide confidence levels that accurately reflect true prediction accuracy.

\item \textbf{Computational efficiency} is non-negotiable for real-time survey operations. Inference times must be milliseconds, not seconds, to process thousands of events as observations arrive.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The Research Gap}
\label{sec:gap}

The literature review reveals a clear gap at the intersection of microlensing classification and sequential deep learning: \emph{there exists no end-to-end neural network architecture that processes raw photometric time series to classify binary microlensing events in real time as observations arrive}.

Existing approaches fall into two categories, each with fundamental limitations:

\textbf{Traditional methods} ($\chi^2$ fitting, Bayesian inference, expert inspection) can achieve high accuracy given complete light curves and sufficient computational resources, but they scale poorly to Roman-era detection rates. The computational cost of binary model fitting prohibits real-time classification of thousands of simultaneous events, and manual inspection introduces subjective biases while requiring unsustainable human effort.

\textbf{Machine learning approaches} demonstrated in other time-domain contexts (supernova classification, variable star typing, exoplanet detection) have established that neural networks can learn complex temporal patterns from raw data and provide rapid inference suitable for alert streams. However, applications to microlensing have focused either on event detection (distinguishing microlensing from non-microlensing) or have required pre-computed model parameters as features, failing to provide the end-to-end, real-time classification capability needed for Roman operations.

The specific requirements for Roman-era binary microlensing classification are:

\begin{enumerate}
\item \textbf{Raw photometry input}: The classifier must process flux measurements and observation times directly, without requiring computationally expensive model fits as intermediate features.

\item \textbf{Sequential processing}: The architecture must handle variable-length light curves and support real-time classification as observations arrive, not just final classification using complete events.

\item \textbf{Hierarchical discrimination}: The model must first detect genuine microlensing events (any magnification), then distinguish binary from single-lens configurations—two fundamentally different tasks requiring specialized representations.

\item \textbf{Computational efficiency}: Inference times must be sub-millisecond per event to enable real-time processing of thousands of simultaneous events in Roman alert streams.

\item \textbf{Calibrated uncertainties}: The system must provide well-calibrated probability estimates, where reported confidence levels accurately reflect true prediction accuracy, to guide follow-up resource allocation.

\item \textbf{Physical interpretability}: Performance degradation at large impact parameters should reflect genuine physical detection limits (binary events becoming indistinguishable from PSPL events) rather than algorithmic failures.
\end{enumerate}

This thesis addresses this gap through a CNN-GRU hierarchical architecture trained on physically accurate synthetic data. The convolutional layers extract local temporal features (caustic crossings), the GRU layers maintain long-term memory across the 72-day observing season, and the hierarchical classification structure mirrors the logical decomposition of the problem (event detection, then binary discrimination). The complete system achieves sub-millisecond inference on typical GPU hardware, enabling deployment in operational survey pipelines.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Summary}

The classification of binary microlensing events exists at the intersection of mature observational techniques, well-understood physical models, and emerging machine learning capabilities. Ground-based surveys have demonstrated that binary events produce detectable signatures in photometric time series, but current classification methods—whether traditional model fitting or expert visual inspection—will not scale to the Roman Space Telescope's anticipated detection rates.

Machine learning applications in other time-domain astronomy domains have established that neural networks can learn complex temporal patterns from raw data, achieve human-level classification performance, and provide the millisecond-scale inference required for real-time alert processing. Sequential architectures combining convolutional feature extraction with recurrent memory have proven particularly effective for variable-length time series with irregular sampling.

However, a critical gap remains: no existing system provides end-to-end binary microlensing classification directly from raw photometry with the computational efficiency and hierarchical structure needed for Roman operations. The following chapters describe our approach to filling this gap through a CNN-GRU hierarchical classifier trained on synthetic data, systematically evaluated across completeness levels and physical parameters, and benchmarked against traditional methods to quantify performance trade-offs and establish the operational capabilities needed for next-generation surveys.